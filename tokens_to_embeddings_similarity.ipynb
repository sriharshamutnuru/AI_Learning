{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f88a56a6",
   "metadata": {},
   "source": [
    "# üß† Tokenization ‚Üí Embedding ‚Üí Similarity Demo\n",
    "This notebook demonstrates the full workflow of text tokenization, embedding generation, and similarity comparison using Hugging Face & SentenceTransformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install required libraries\n",
    "!pip install transformers sentence-transformers --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20777e06",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221d53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Sample text\n",
    "text = \"Artificial Intelligence is transforming industries.\"\n",
    "\n",
    "# Tokenize text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Convert tokens to IDs\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(\"Token IDs:\", token_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a6d175",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c788849",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a lightweight model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    \"Artificial Intelligence is transforming industries.\",\n",
    "    \"Machine learning is changing business processes.\",\n",
    "    \"Cooking recipes require precision and creativity.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0247fa44",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Cosine Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc65a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import util\n",
    "import pandas as pd\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cosine_sim = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "# Display as a DataFrame\n",
    "df = pd.DataFrame(cosine_sim.cpu().numpy(), index=sentences, columns=sentences)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245684e",
   "metadata": {},
   "source": [
    "## ‚úÖ Interpretation\n",
    "- Values close to **1.0** indicate high semantic similarity.\n",
    "- Sentences 1 and 2 should be more similar than 1 and 3.\n",
    "- You can try adding your own sentences to test the embeddings.\n",
    "\n",
    "This forms the foundational concept of **semantic search** and **retrieval-augmented generation (RAG)**."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
