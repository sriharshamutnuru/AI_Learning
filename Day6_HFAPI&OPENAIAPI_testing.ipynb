{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-IKLIgkUL01",
        "outputId": "60fcc01f-659a-4b7c-f04e-17cf89f886df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "article = \"\"\"\n",
        "Artificial Intelligence (AI) is rapidly transforming how businesses operate...\n",
        "The Quiet Revolution: How Generative AI Is Rewriting the Rules of Work and Creativity\n",
        "\n",
        "In the last five years, artificial intelligence has shifted from being a futuristic curiosity to a central force shaping modern work, communication, and creativity. Among the various branches of AI, Generative AI (GenAI) stands out for its ability to create — to write, design, compose, and even reason — in ways that mimic human intelligence. What started as simple text generation has evolved into multimodal systems capable of blending language, image, and sound into coherent, contextually relevant outputs. But as these systems grow more capable, a fundamental question arises: are we witnessing the augmentation of human creativity or the quiet automation of it?\n",
        "\n",
        "From Prediction to Creation\n",
        "\n",
        "Traditional AI systems were designed to recognize patterns and make predictions: identify spam emails, classify images, or forecast stock prices. Generative AI, however, works differently. Instead of simply predicting the next number in a sequence, it predicts the next word, pixel, or note in a creative context. Large Language Models (LLMs) like GPT-4, Claude, and Gemini have learned to internalize linguistic and conceptual relationships from vast amounts of data — from literature to code repositories — allowing them to generate original and contextually adaptive content.\n",
        "\n",
        "At its core, generative AI is probabilistic. Each word it produces is the most likely continuation of the prior context, yet the staggering scale of its training allows for nuance, creativity, and stylistic variation. A well-tuned prompt can yield anything from a Shakespearean sonnet to a product marketing plan. The distinction between prediction and imagination, once clearly human, has begun to blur.\n",
        "\n",
        "The New Knowledge Worker\n",
        "\n",
        "The modern knowledge worker — from software engineers to analysts and designers — is undergoing a profound transformation. Where once technical expertise or creativity was a limiting factor, GenAI now acts as an amplifier. An analyst can use an AI agent to summarize 500 pages of documentation, generate code for a data pipeline, and produce visual insights in minutes. A marketer can draft campaigns, experiment with tone, and analyze audience sentiment almost instantaneously.\n",
        "\n",
        "Yet, this democratization of creation is not without consequences. As GenAI lowers the barrier to entry, the competitive advantage shifts from what you know to how you use AI to extend your knowledge. In the same way calculators transformed mathematics from computation to problem-solving, GenAI is shifting the cognitive emphasis of work from manual production to strategic orchestration. The winners of this new era are not those who fear automation, but those who learn to collaborate with it.\n",
        "\n",
        "The Paradox of Authenticity\n",
        "\"\"\"\n",
        "summary = summarizer(article, max_length=150, min_length=60, do_sample=False)\n",
        "print(summary[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtHIY4wVUYjJ",
        "outputId": "2057844c-933a-456f-fc0e-d75ac2068b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial Intelligence (AI) is rapidly transforming how businesses operate. Generative AI (GenAI) stands out for its ability to create — to write, design, compose, and even reason. As these systems grow more capable, a fundamental question arises: are we witnessing the augmentation of human creativity or the quiet automation of it?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Summarize the following article in concise form.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Artificial Intelligence (AI) is rapidly transforming how businesses operate... The Quiet Revolution: How Generative AI Is Rewriting the Rules of Work and Creativity In the last five years, artificial intelligence has shifted from being a futuristic curiosity to a central force shaping modern work, communication, and creativity. Among the various branches of AI, Generative AI (GenAI) stands out for its ability to create — to write, design, compose, and even reason — in ways that mimic human intelligence. What started as simple text generation has evolved into multimodal systems capable of blending language, image, and sound into coherent, contextually relevant outputs. But as these systems grow more capable, a fundamental question arises: are we witnessing the augmentation of human creativity or the quiet automation of it? From Prediction to Creation Traditional AI systems were designed to recognize patterns and make predictions: identify spam emails, classify images, or forecast stock prices. Generative AI, however, works differently. Instead of simply predicting the next number in a sequence, it predicts the next word, pixel, or note in a creative context. Large Language Models (LLMs) like GPT-4, Claude, and Gemini have learned to internalize linguistic and conceptual relationships from vast amounts of data — from literature to code repositories — allowing them to generate original and contextually adaptive content. At its core, generative AI is probabilistic. Each word it produces is the most likely continuation of the prior context, yet the staggering scale of its training allows for nuance, creativity, and stylistic variation. A well-tuned prompt can yield anything from a Shakespearean sonnet to a product marketing plan. The distinction between prediction and imagination, once clearly human, has begun to blur. The New Knowledge Worker The modern knowledge worker — from software engineers to analysts and designers — is undergoing a profound transformation. Where once technical expertise or creativity was a limiting factor, GenAI now acts as an amplifier. An analyst can use an AI agent to summarize 500 pages of documentation, generate code for a data pipeline, and produce visual insights in minutes. A marketer can draft campaigns, experiment with tone, and analyze audience sentiment almost instantaneously. Yet, this democratization of creation is not without consequences. As GenAI lowers the barrier to entry, the competitive advantage shifts from what you know to how you use AI to extend your knowledge. In the same way calculators transformed mathematics from computation to problem-solving, GenAI is shifting the cognitive emphasis of work from manual production to strategic orchestration. The winners of this new era are not those who fear automation, but those who learn to collaborate with it.\"}\n",
        "    ]\n",
        ")\n",
        "summary_openai = response.choices[0].message.content\n",
        "print(\"OpenAI Summary:\\n\", summary_openai)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msW4zjPOVO3D",
        "outputId": "2b368415-70df-40b3-da71-8ad2afc5edcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "OpenAI Summary:\n",
            " Artificial Intelligence (AI) has dramatically shifted business operations, especially with the rise of Generative AI (GenAI), which can create content in ways that mimic human thought. Unlike traditional AI that focuses on predictions, GenAI generates diverse outputs—text, images, and sounds—by understanding and synthesizing vast data. This evolution challenges the line between human imagination and machine-generated content, empowering modern knowledge workers, such as analysts and marketers, to enhance their productivity significantly. However, as GenAI democratizes content creation, the competitive edge now relies on how effectively individuals integrate AI into their work rather than solely on their technical skills, marking a shift towards strategic collaboration with AI rather than fear of automation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n🟦 Hugging Face Summary:\\n\", summary[0]['summary_text'])\n",
        "print(\"\\n🟩 OpenAI Summary:\\n\", summary_openai)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3YRXJxyWWvX",
        "outputId": "3a4d5eb7-432e-4154-c77c-e1d0d054e204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🟦 Hugging Face Summary:\n",
            " Artificial Intelligence (AI) is rapidly transforming how businesses operate. Generative AI (GenAI) stands out for its ability to create — to write, design, compose, and even reason. As these systems grow more capable, a fundamental question arises: are we witnessing the augmentation of human creativity or the quiet automation of it?\n",
            "\n",
            "🟩 OpenAI Summary:\n",
            " Artificial Intelligence (AI) has dramatically shifted business operations, especially with the rise of Generative AI (GenAI), which can create content in ways that mimic human thought. Unlike traditional AI that focuses on predictions, GenAI generates diverse outputs—text, images, and sounds—by understanding and synthesizing vast data. This evolution challenges the line between human imagination and machine-generated content, empowering modern knowledge workers, such as analysts and marketers, to enhance their productivity significantly. However, as GenAI democratizes content creation, the competitive edge now relies on how effectively individuals integrate AI into their work rather than solely on their technical skills, marking a shift towards strategic collaboration with AI rather than fear of automation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "\n",
        "context = \"\"\"\n",
        "Hugging Face is an AI company that develops tools for building applications using machine learning.\n",
        "It is best known for its Transformers library that provides thousands of pre-trained models.\n",
        "\"\"\"\n",
        "question = \"What is Hugging Face best known for?\"\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "print(\"Answer:\", result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "bfc3aadcc20d4ed1bf4121825e932396",
            "e2d26de5d58f46e78034dd3b5aaaa024",
            "978b261233ce4bbb8c1784f68ace5ffc",
            "20491eeed4ea41cfb88cd036f99ff379",
            "4d74ebbc4c9a42d8b42e603b6fb2c023",
            "bcb9df6c60d8441e90f20a0e9ccb4e84",
            "73b7a7a107614e2197cb2292f947b8da",
            "874556f8afcc4c3ba74edd5f9a0ab454",
            "894574fd66be4ab59b3632355d2c42fb",
            "d21e115c78c54ee0ade6def96778d646",
            "7f2c6fd67c1446249103711b2462291e",
            "beadfc5e0970476da2fac2f35d3ed647",
            "859a48da4ae54c5fbea6521839808ccc",
            "5dd5ddb23f7740fdaa289192c580b4fa",
            "42a83b6c03694022af46f5bc9b85bf09",
            "4cf1316a77f04d89a1c46270826c90c3",
            "95bd981992824ad79bfe70664d120014",
            "939b1c74a9fd440a93f25392111ec0a8",
            "abfe847b81ae4e46aefcf7ab6833ff10",
            "5b30fa8eb53747ef9ea7ee9feb5ef068",
            "a2e89e0e05f04184bd56f8ffe51a23e4",
            "d7a06a97f1564cf8ad2573baecc886d2",
            "928cf35ba5534bcc94551a73cac20561",
            "7061b5103e3d422a9efd9bd6cafdb9b3",
            "5b2006ccb3304637a9c4f6fd64dbcd3b",
            "ab1ee766ea82401c83c06d1696161901",
            "f4117bbc9a4347faaf1441dccde226f8",
            "38f5999b3cbc4514bdd81d3deabcdd34",
            "463cf51e8af640f2ba23455aa7b19666",
            "51dc7b85685f4fc08b7ecb1483c17d86",
            "ff6989175a5543be9a6046f09bb4b747",
            "96d6a0edb25d4b24b9d8b8a8f4820662",
            "95ac49d374ad4ee4b9ee377911a40d8d",
            "50012dcb86de4eebb00ea1886c0640f7",
            "04f4058825454ad4a964942dd5ada1c9",
            "6c86b33aee5f4d04a8daaa24abefa716",
            "44d318c989b6436a969c47edc70b2f4e",
            "44cab823c362466587097215a1170201",
            "354e857c83cd402aaa517a21150161be",
            "00dcd22d43be48ebae52e62064066ac9",
            "94cc4cae40d64f6bb34cd87380f9e003",
            "abf6447ea9aa4e65babf2d49ec64ff5d",
            "eb77f0e5b17348bb8a5edab9569fdd4b",
            "b755e5a7b4fe4148b8fd89867932e1e4",
            "cdd1ac91b1b84a749e0270bd43bc15c1",
            "a000a03b37ed424dbac675a25e6c2277",
            "b7536ea7d7ae464fb5d620bdc8b2b7b4",
            "e669168754c44528ad2da03bfdf09be3",
            "6c4ec8eaecea4bdf9da6827e829aa3d8",
            "6a212276dbc840f4a39885ab4455f530",
            "810723d2d50b4b8780e9460fe603c7a4",
            "de28e74696d24f7d97262a8f52984f67",
            "061ca138aa5a473ca047f62a899d0f7e",
            "7eeacd906e974586840a551c8796f41c",
            "d17ad8d4f0684170aad8f74ae03f7ede"
          ]
        },
        "id": "Q1wK2HKKWlqc",
        "outputId": "7e718e9d-a695-4f9e-e27d-65c09ff3122a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfc3aadcc20d4ed1bf4121825e932396"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "beadfc5e0970476da2fac2f35d3ed647"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "928cf35ba5534bcc94551a73cac20561"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50012dcb86de4eebb00ea1886c0640f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdd1ac91b1b84a749e0270bd43bc15c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Transformers library\n"
          ]
        }
      ]
    }
  ]
}