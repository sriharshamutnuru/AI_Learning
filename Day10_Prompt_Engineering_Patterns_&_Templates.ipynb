{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnRIseaoPmdXZS1kZa941S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sriharshamutnuru/AI_Learning/blob/main/Day10_Prompt_Engineering_Patterns_%26_Templates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZQsflp1A6iU",
        "outputId": "a4d7dd52-8bcc-409f-cd2e-9ae875c1d692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§  Final Prompt Sent to Model:\n",
            "\n",
            "You are an intelligent assistant.\n",
            "\n",
            "Task:\n",
            "Extract the main problems and their corresponding solutions from the text.\n",
            "\n",
            "Examples:\n",
            "Example 1:\n",
            "Input: Users often face login issues due to expired tokens.\n",
            "Output: {\"problem\": \"login issues\", \"solution\": \"refresh the authentication token\"}\n",
            "\n",
            "Example 2:\n",
            "Input: System performance drops when too many concurrent jobs run.\n",
            "Output: {\"problem\": \"performance degradation\", \"solution\": \"limit concurrent jobs\"}\n",
            "\n",
            "Context:\n",
            "\n",
            "Our Azure environment experiences frequent backup failures.\n",
            "The logs show timeouts when connecting to storage accounts.\n",
            "\n",
            "\n",
            "Return the result in valid JSON.\n",
            "\n",
            "\n",
            "ðŸ§¾ Model Response:\n",
            "\n",
            "```json\n",
            "{\"problem\": \"backup failures\", \"solution\": \"investigate and resolve storage account connection timeouts\"}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ðŸ“˜ Day 10 â€” Prompt Engineering Patterns & Templates\n",
        "# ============================================================\n",
        "\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "# --- Step 1: Create a Prompt Template Function ---\n",
        "\n",
        "def build_prompt(context: str, instructions: str, examples: list = None) -> str:\n",
        "    \"\"\"\n",
        "    Builds a structured prompt combining context, examples, and instructions.\n",
        "    \"\"\"\n",
        "    base_prompt = f\"You are an intelligent assistant.\\n\\nTask:\\n{instructions}\\n\\n\"\n",
        "\n",
        "    if examples:\n",
        "        base_prompt += \"Examples:\\n\"\n",
        "        for i, ex in enumerate(examples, 1):\n",
        "            base_prompt += f\"Example {i}:\\nInput: {ex['input']}\\nOutput: {ex['output']}\\n\\n\"\n",
        "\n",
        "    base_prompt += f\"Context:\\n{context}\\n\\nReturn the result in valid JSON.\\n\"\n",
        "    return base_prompt\n",
        "\n",
        "\n",
        "# --- Step 2: Define Context, Instructions, Examples ---\n",
        "\n",
        "instructions = \"Extract the main problems and their corresponding solutions from the text.\"\n",
        "examples = [\n",
        "    {\n",
        "        \"input\": \"Users often face login issues due to expired tokens.\",\n",
        "        \"output\": '{\"problem\": \"login issues\", \"solution\": \"refresh the authentication token\"}'\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"System performance drops when too many concurrent jobs run.\",\n",
        "        \"output\": '{\"problem\": \"performance degradation\", \"solution\": \"limit concurrent jobs\"}'\n",
        "    }\n",
        "]\n",
        "\n",
        "context = \"\"\"\n",
        "Our Azure environment experiences frequent backup failures.\n",
        "The logs show timeouts when connecting to storage accounts.\n",
        "\"\"\"\n",
        "\n",
        "# --- Step 3: Build Prompt & Run ---\n",
        "\n",
        "prompt = build_prompt(context, instructions, examples)\n",
        "print(\"ðŸ§  Final Prompt Sent to Model:\\n\")\n",
        "print(prompt)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a structured reasoning assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature=0.3,\n",
        ")\n",
        "\n",
        "print(\"\\nðŸ§¾ Model Response:\\n\")\n",
        "print(response.choices[0].message.content)\n"
      ]
    }
  ]
}