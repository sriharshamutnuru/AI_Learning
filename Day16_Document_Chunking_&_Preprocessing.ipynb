{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOG3YVX/ve79MtshPFIZzR/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sriharshamutnuru/AI_Learning/blob/main/Day16_Document_Chunking_%26_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "tg8oKJ2NvwHP",
        "outputId": "119154dd-0e98-479b-a783-7831d8375e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨áÔ∏è Downloading ai_overview.pdf ...\n",
            "‚¨áÔ∏è Downloading data_engineering.pdf ...\n",
            "\n",
            "‚úÖ PDFs ready in /content/sample_pdfs/\n",
            "total 1.7M\n",
            "-rw-r--r-- 1 root root 1012K Oct 28 12:21 ai_overview.pdf\n",
            "-rw-r--r-- 1 root root  1.2K Oct 28 12:17 azure_cloud_overview.pdf\n",
            "-rw-r--r-- 1 root root  660K Oct 28 12:17 data_engineering_basics.pdf\n",
            "-rw-r--r-- 1 root root   264 Oct 28 12:21 data_engineering.pdf\n",
            "\n",
            "üìò Processing: data_engineering.pdf\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileDataError",
          "evalue": "Failed to open file '/content/sample_pdfs/data_engineering.pdf'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFzErrorFormat\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymupdf/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[1;32m   2991\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2992\u001b[0;31m                         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmupdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfz_open_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2993\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymupdf/mupdf.py\u001b[0m in \u001b[0;36mfz_open_document\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m  48461\u001b[0m     \"\"\"\n\u001b[0;32m> 48462\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_mupdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfz_open_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  48463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFzErrorFormat\u001b[0m: code=7: no objects found",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mFileDataError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4027776490.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpdf_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpdf_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nüìò Processing: {pdf_file.name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"üßæ Text length: {len(text)} characters\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4027776490.py\u001b[0m in \u001b[0;36mextract_text_from_pdf\u001b[0;34m(pdf_path)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mfitz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymupdf/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[1;32m   2993\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mg_exceptions_verbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0mexception_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mFileDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Failed to open file {filename!r}.'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileDataError\u001b[0m: Failed to open file '/content/sample_pdfs/data_engineering.pdf'."
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# üìò Day 16 ‚Äî Working Version (Chunking Real PDFs)\n",
        "# ============================================================\n",
        "\n",
        "!pip install --quiet pymupdf langchain tiktoken pandas matplotlib requests\n",
        "\n",
        "import os, requests, fitz\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import tiktoken\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# STEP 1 ‚Äî Download Stable, Public PDFs\n",
        "# ============================================================\n",
        "os.makedirs(\"/content/sample_pdfs\", exist_ok=True)\n",
        "\n",
        "pdf_urls = {\n",
        "    \"ai_overview.pdf\": \"https://arxiv.org/pdf/2001.09977.pdf\",  # AI survey\n",
        "    \"data_engineering.pdf\": \"https://storage.googleapis.com/gweb-cloudblog-publish/images/Data_Lake_on_GCP_whitepaper.max-1300x1300.jpgpagespeed.ce.U6kIvYz8-F.pdf\"  # Google Data Lake whitepaper\n",
        "}\n",
        "\n",
        "for name, url in pdf_urls.items():\n",
        "    print(f\"‚¨áÔ∏è Downloading {name} ...\")\n",
        "    r = requests.get(url)\n",
        "    with open(f\"/content/sample_pdfs/{name}\", \"wb\") as f:\n",
        "        f.write(r.content)\n",
        "\n",
        "print(\"\\n‚úÖ PDFs ready in /content/sample_pdfs/\")\n",
        "!ls -lh /content/sample_pdfs\n",
        "\n",
        "# ============================================================\n",
        "# STEP 2 ‚Äî Extract Text, Chunk & Save\n",
        "# ============================================================\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text(\"text\") + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "def count_tokens(text):\n",
        "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    return len(enc.encode(text))\n",
        "\n",
        "def chunk_text(text, chunk_size=1000, overlap=150):\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=overlap,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\"]\n",
        "    )\n",
        "    return splitter.split_text(text)\n",
        "\n",
        "pdf_dir = Path(\"/content/sample_pdfs\")\n",
        "all_chunks = []\n",
        "\n",
        "for pdf_file in pdf_dir.glob(\"*.pdf\"):\n",
        "    print(f\"\\nüìò Processing: {pdf_file.name}\")\n",
        "    text = extract_text_from_pdf(pdf_file)\n",
        "    print(f\"üßæ Text length: {len(text)} characters\")\n",
        "\n",
        "    chunks = chunk_text(text, chunk_size=1000, overlap=150)\n",
        "    print(f\"‚úÖ Extracted {len(chunks)} chunks\")\n",
        "\n",
        "    for i, chunk in enumerate(chunks, 1):\n",
        "        all_chunks.append({\n",
        "            \"pdf_name\": pdf_file.name,\n",
        "            \"chunk_id\": i,\n",
        "            \"token_count\": count_tokens(chunk),\n",
        "            \"text_preview\": chunk[:300].replace(\"\\n\", \" \") + \"...\"\n",
        "        })\n",
        "\n",
        "# ============================================================\n",
        "# STEP 3 ‚Äî Save Results & Visualize\n",
        "# ============================================================\n",
        "if all_chunks:\n",
        "    df = pd.DataFrame(all_chunks)\n",
        "    df.to_csv(\"chunked_output.csv\", index=False)\n",
        "    print(\"\\n‚úÖ Chunked output saved as chunked_output.csv\")\n",
        "    print(f\"üìä Total Chunks: {len(df)}\")\n",
        "    display(df.head(5))\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    df[\"token_count\"].hist(bins=20)\n",
        "    plt.title(\"Distribution of Token Counts per Chunk\")\n",
        "    plt.xlabel(\"Tokens per Chunk\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No valid text extracted. Check PDF sources.\")"
      ]
    }
  ]
}